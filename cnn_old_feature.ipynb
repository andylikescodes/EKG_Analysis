{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#import python packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#import EKG analysis packages\n",
    "import challengeOld as challenge\n",
    "import waveOld as wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "records = wave.getRecords('~', _not=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feat_list = []\n",
    "for record in records[0]:\n",
    "    signal = challenge.Signal(record, wave.load(record))\n",
    "    feat_list.append(challenge.feature_extract(signal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "labels=[]\n",
    "N = 0;\n",
    "O = 0;\n",
    "A = 0;\n",
    "NO = 0;\n",
    "for label in records[1]:\n",
    "    if label == 'N':\n",
    "        N+=1;\n",
    "        labels.append(0)\n",
    "    elif label == 'O':\n",
    "        O+=1;\n",
    "        labels.append(1)\n",
    "    elif label == 'A':\n",
    "        A+=1;\n",
    "        labels.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8244\n"
     ]
    }
   ],
   "source": [
    "n_all = len(labels)\n",
    "print(n_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print (NO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6125667151868025, 0.2979136341581756, 0.08951965065502183]\n"
     ]
    }
   ],
   "source": [
    "class_weights = [N/n_all, O/n_all, A/n_all]\n",
    "print (class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat_list, labels, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "X_train = scale(X_train)\n",
    "X_test = scale(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=12)\n",
    "pca.fit(X_train)\n",
    "\n",
    "X_train_PCA = pca.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pca.fit(X_test)\n",
    "X_test_PCA = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6595\n"
     ]
    }
   ],
   "source": [
    "print (len(X_train_PCA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 128\n",
    "learning_rate = 0.0001\n",
    "num_examples = len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.int32)\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "one_hot_y = tf.one_hot(y, 3)\n",
    "class_w = tf.constant(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fw1 = tf.Variable(tf.truncated_normal([12, 20], mean=0, stddev=0.1))\n",
    "fb1 = tf.Variable(tf.zeros([20]))\n",
    "fw2 = tf.Variable(tf.truncated_normal([20, 20], mean=0, stddev=0.1))\n",
    "fb2 = tf.Variable(tf.zeros([20]))\n",
    "fw3 = tf.Variable(tf.truncated_normal([20, 3], mean=0, stddev=0.1))\n",
    "fb3 = tf.Variable(tf.zeros([3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#fully connect layer 1, 58 => 80\n",
    "fully_layer_1 = tf.add(tf.matmul(X, fw1), fb1)\n",
    "fully_layer_1 = tf.nn.relu(fully_layer_1)\n",
    "#fully_layer_1 = tf.nn.dropout(fully_layer_1, keep_prob)\n",
    "\n",
    "#fully connect layer 2, 80 => 80\n",
    "fully_layer_2 = tf.add(tf.matmul(fully_layer_1, fw2), fb2)\n",
    "fully_layer_2 = tf.nn.relu(fully_layer_2)\n",
    "#fully_layer_2 = tf.nn.dropout(fully_layer_2, keep_prob)\n",
    "\n",
    "#output layer => 80 => 3\n",
    "logits = tf.multiply(tf.add(tf.matmul(fully_layer_2, fw3), fb3), class_w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#train the model\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss_operation)\n",
    "\n",
    "#accuracy and loss\n",
    "correct_prediction = tf.equal(tf.argmax(logits,1), tf.argmax(one_hot_y,1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def evaluate(X_data, y_data, class_weights):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_X, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={X: batch_X, y: batch_y, class_w: class_weights})\n",
    "        total_accuracy += (accuracy * len(batch_X))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS 1..\n",
      "training_accuracy = 0.389\n",
      "validation_accuracy = 0.389\n",
      "\n",
      "EPOCHS 2..\n",
      "training_accuracy = 0.390\n",
      "validation_accuracy = 0.390\n",
      "\n",
      "EPOCHS 3..\n",
      "training_accuracy = 0.393\n",
      "validation_accuracy = 0.393\n",
      "\n",
      "EPOCHS 4..\n",
      "training_accuracy = 0.394\n",
      "validation_accuracy = 0.394\n",
      "\n",
      "EPOCHS 5..\n",
      "training_accuracy = 0.396\n",
      "validation_accuracy = 0.396\n",
      "\n",
      "EPOCHS 6..\n",
      "training_accuracy = 0.398\n",
      "validation_accuracy = 0.398\n",
      "\n",
      "EPOCHS 7..\n",
      "training_accuracy = 0.396\n",
      "validation_accuracy = 0.396\n",
      "\n",
      "EPOCHS 8..\n",
      "training_accuracy = 0.399\n",
      "validation_accuracy = 0.399\n",
      "\n",
      "EPOCHS 9..\n",
      "training_accuracy = 0.399\n",
      "validation_accuracy = 0.399\n",
      "\n",
      "EPOCHS 10..\n",
      "training_accuracy = 0.401\n",
      "validation_accuracy = 0.401\n",
      "\n",
      "EPOCHS 11..\n",
      "training_accuracy = 0.406\n",
      "validation_accuracy = 0.406\n",
      "\n",
      "EPOCHS 12..\n",
      "training_accuracy = 0.409\n",
      "validation_accuracy = 0.409\n",
      "\n",
      "EPOCHS 13..\n",
      "training_accuracy = 0.411\n",
      "validation_accuracy = 0.411\n",
      "\n",
      "EPOCHS 14..\n",
      "training_accuracy = 0.411\n",
      "validation_accuracy = 0.411\n",
      "\n",
      "EPOCHS 15..\n",
      "training_accuracy = 0.415\n",
      "validation_accuracy = 0.415\n",
      "\n",
      "EPOCHS 16..\n",
      "training_accuracy = 0.415\n",
      "validation_accuracy = 0.415\n",
      "\n",
      "EPOCHS 17..\n",
      "training_accuracy = 0.417\n",
      "validation_accuracy = 0.417\n",
      "\n",
      "EPOCHS 18..\n",
      "training_accuracy = 0.420\n",
      "validation_accuracy = 0.420\n",
      "\n",
      "EPOCHS 19..\n",
      "training_accuracy = 0.426\n",
      "validation_accuracy = 0.426\n",
      "\n",
      "EPOCHS 20..\n",
      "training_accuracy = 0.428\n",
      "validation_accuracy = 0.428\n",
      "\n",
      "EPOCHS 21..\n",
      "training_accuracy = 0.433\n",
      "validation_accuracy = 0.433\n",
      "\n",
      "EPOCHS 22..\n",
      "training_accuracy = 0.438\n",
      "validation_accuracy = 0.438\n",
      "\n",
      "EPOCHS 23..\n",
      "training_accuracy = 0.439\n",
      "validation_accuracy = 0.439\n",
      "\n",
      "EPOCHS 24..\n",
      "training_accuracy = 0.441\n",
      "validation_accuracy = 0.441\n",
      "\n",
      "EPOCHS 25..\n",
      "training_accuracy = 0.447\n",
      "validation_accuracy = 0.447\n",
      "\n",
      "EPOCHS 26..\n",
      "training_accuracy = 0.449\n",
      "validation_accuracy = 0.449\n",
      "\n",
      "EPOCHS 27..\n",
      "training_accuracy = 0.456\n",
      "validation_accuracy = 0.456\n",
      "\n",
      "EPOCHS 28..\n",
      "training_accuracy = 0.459\n",
      "validation_accuracy = 0.459\n",
      "\n",
      "EPOCHS 29..\n",
      "training_accuracy = 0.461\n",
      "validation_accuracy = 0.461\n",
      "\n",
      "EPOCHS 30..\n",
      "training_accuracy = 0.465\n",
      "validation_accuracy = 0.465\n",
      "\n",
      "EPOCHS 31..\n",
      "training_accuracy = 0.466\n",
      "validation_accuracy = 0.466\n",
      "\n",
      "EPOCHS 32..\n",
      "training_accuracy = 0.465\n",
      "validation_accuracy = 0.465\n",
      "\n",
      "EPOCHS 33..\n",
      "training_accuracy = 0.468\n",
      "validation_accuracy = 0.468\n",
      "\n",
      "EPOCHS 34..\n",
      "training_accuracy = 0.472\n",
      "validation_accuracy = 0.472\n",
      "\n",
      "EPOCHS 35..\n",
      "training_accuracy = 0.477\n",
      "validation_accuracy = 0.477\n",
      "\n",
      "EPOCHS 36..\n",
      "training_accuracy = 0.479\n",
      "validation_accuracy = 0.479\n",
      "\n",
      "EPOCHS 37..\n",
      "training_accuracy = 0.478\n",
      "validation_accuracy = 0.478\n",
      "\n",
      "EPOCHS 38..\n",
      "training_accuracy = 0.480\n",
      "validation_accuracy = 0.480\n",
      "\n",
      "EPOCHS 39..\n",
      "training_accuracy = 0.483\n",
      "validation_accuracy = 0.483\n",
      "\n",
      "EPOCHS 40..\n",
      "training_accuracy = 0.485\n",
      "validation_accuracy = 0.485\n",
      "\n",
      "EPOCHS 41..\n",
      "training_accuracy = 0.486\n",
      "validation_accuracy = 0.486\n",
      "\n",
      "EPOCHS 42..\n",
      "training_accuracy = 0.489\n",
      "validation_accuracy = 0.489\n",
      "\n",
      "EPOCHS 43..\n",
      "training_accuracy = 0.492\n",
      "validation_accuracy = 0.492\n",
      "\n",
      "EPOCHS 44..\n",
      "training_accuracy = 0.494\n",
      "validation_accuracy = 0.494\n",
      "\n",
      "EPOCHS 45..\n",
      "training_accuracy = 0.497\n",
      "validation_accuracy = 0.497\n",
      "\n",
      "EPOCHS 46..\n",
      "training_accuracy = 0.498\n",
      "validation_accuracy = 0.498\n",
      "\n",
      "EPOCHS 47..\n",
      "training_accuracy = 0.502\n",
      "validation_accuracy = 0.502\n",
      "\n",
      "EPOCHS 48..\n",
      "training_accuracy = 0.504\n",
      "validation_accuracy = 0.504\n",
      "\n",
      "EPOCHS 49..\n",
      "training_accuracy = 0.508\n",
      "validation_accuracy = 0.508\n",
      "\n",
      "EPOCHS 50..\n",
      "training_accuracy = 0.513\n",
      "validation_accuracy = 0.513\n",
      "\n",
      "EPOCHS 51..\n",
      "training_accuracy = 0.515\n",
      "validation_accuracy = 0.515\n",
      "\n",
      "EPOCHS 52..\n",
      "training_accuracy = 0.516\n",
      "validation_accuracy = 0.516\n",
      "\n",
      "EPOCHS 53..\n",
      "training_accuracy = 0.515\n",
      "validation_accuracy = 0.515\n",
      "\n",
      "EPOCHS 54..\n",
      "training_accuracy = 0.520\n",
      "validation_accuracy = 0.520\n",
      "\n",
      "EPOCHS 55..\n",
      "training_accuracy = 0.520\n",
      "validation_accuracy = 0.520\n",
      "\n",
      "EPOCHS 56..\n",
      "training_accuracy = 0.523\n",
      "validation_accuracy = 0.523\n",
      "\n",
      "EPOCHS 57..\n",
      "training_accuracy = 0.525\n",
      "validation_accuracy = 0.525\n",
      "\n",
      "EPOCHS 58..\n",
      "training_accuracy = 0.525\n",
      "validation_accuracy = 0.525\n",
      "\n",
      "EPOCHS 59..\n",
      "training_accuracy = 0.532\n",
      "validation_accuracy = 0.532\n",
      "\n",
      "EPOCHS 60..\n",
      "training_accuracy = 0.535\n",
      "validation_accuracy = 0.535\n",
      "\n",
      "EPOCHS 61..\n",
      "training_accuracy = 0.537\n",
      "validation_accuracy = 0.537\n",
      "\n",
      "EPOCHS 62..\n",
      "training_accuracy = 0.536\n",
      "validation_accuracy = 0.536\n",
      "\n",
      "EPOCHS 63..\n",
      "training_accuracy = 0.535\n",
      "validation_accuracy = 0.535\n",
      "\n",
      "EPOCHS 64..\n",
      "training_accuracy = 0.537\n",
      "validation_accuracy = 0.537\n",
      "\n",
      "EPOCHS 65..\n",
      "training_accuracy = 0.541\n",
      "validation_accuracy = 0.541\n",
      "\n",
      "EPOCHS 66..\n",
      "training_accuracy = 0.545\n",
      "validation_accuracy = 0.545\n",
      "\n",
      "EPOCHS 67..\n",
      "training_accuracy = 0.545\n",
      "validation_accuracy = 0.545\n",
      "\n",
      "EPOCHS 68..\n",
      "training_accuracy = 0.545\n",
      "validation_accuracy = 0.545\n",
      "\n",
      "EPOCHS 69..\n",
      "training_accuracy = 0.547\n",
      "validation_accuracy = 0.547\n",
      "\n",
      "EPOCHS 70..\n",
      "training_accuracy = 0.548\n",
      "validation_accuracy = 0.548\n",
      "\n",
      "EPOCHS 71..\n",
      "training_accuracy = 0.550\n",
      "validation_accuracy = 0.550\n",
      "\n",
      "EPOCHS 72..\n",
      "training_accuracy = 0.552\n",
      "validation_accuracy = 0.552\n",
      "\n",
      "EPOCHS 73..\n",
      "training_accuracy = 0.552\n",
      "validation_accuracy = 0.552\n",
      "\n",
      "EPOCHS 74..\n",
      "training_accuracy = 0.554\n",
      "validation_accuracy = 0.554\n",
      "\n",
      "EPOCHS 75..\n",
      "training_accuracy = 0.556\n",
      "validation_accuracy = 0.556\n",
      "\n",
      "EPOCHS 76..\n",
      "training_accuracy = 0.559\n",
      "validation_accuracy = 0.559\n",
      "\n",
      "EPOCHS 77..\n",
      "training_accuracy = 0.561\n",
      "validation_accuracy = 0.561\n",
      "\n",
      "EPOCHS 78..\n",
      "training_accuracy = 0.562\n",
      "validation_accuracy = 0.562\n",
      "\n",
      "EPOCHS 79..\n",
      "training_accuracy = 0.562\n",
      "validation_accuracy = 0.562\n",
      "\n",
      "EPOCHS 80..\n",
      "training_accuracy = 0.565\n",
      "validation_accuracy = 0.565\n",
      "\n",
      "EPOCHS 81..\n",
      "training_accuracy = 0.569\n",
      "validation_accuracy = 0.569\n",
      "\n",
      "EPOCHS 82..\n",
      "training_accuracy = 0.569\n",
      "validation_accuracy = 0.569\n",
      "\n",
      "EPOCHS 83..\n",
      "training_accuracy = 0.571\n",
      "validation_accuracy = 0.571\n",
      "\n",
      "EPOCHS 84..\n",
      "training_accuracy = 0.572\n",
      "validation_accuracy = 0.572\n",
      "\n",
      "EPOCHS 85..\n",
      "training_accuracy = 0.572\n",
      "validation_accuracy = 0.572\n",
      "\n",
      "EPOCHS 86..\n",
      "training_accuracy = 0.575\n",
      "validation_accuracy = 0.575\n",
      "\n",
      "EPOCHS 87..\n",
      "training_accuracy = 0.579\n",
      "validation_accuracy = 0.579\n",
      "\n",
      "EPOCHS 88..\n",
      "training_accuracy = 0.580\n",
      "validation_accuracy = 0.580\n",
      "\n",
      "EPOCHS 89..\n",
      "training_accuracy = 0.583\n",
      "validation_accuracy = 0.583\n",
      "\n",
      "EPOCHS 90..\n",
      "training_accuracy = 0.584\n",
      "validation_accuracy = 0.584\n",
      "\n",
      "EPOCHS 91..\n",
      "training_accuracy = 0.585\n",
      "validation_accuracy = 0.585\n",
      "\n",
      "EPOCHS 92..\n",
      "training_accuracy = 0.588\n",
      "validation_accuracy = 0.588\n",
      "\n",
      "EPOCHS 93..\n",
      "training_accuracy = 0.586\n",
      "validation_accuracy = 0.586\n",
      "\n",
      "EPOCHS 94..\n",
      "training_accuracy = 0.585\n",
      "validation_accuracy = 0.585\n",
      "\n",
      "EPOCHS 95..\n",
      "training_accuracy = 0.586\n",
      "validation_accuracy = 0.586\n",
      "\n",
      "EPOCHS 96..\n",
      "training_accuracy = 0.590\n",
      "validation_accuracy = 0.590\n",
      "\n",
      "EPOCHS 97..\n",
      "training_accuracy = 0.591\n",
      "validation_accuracy = 0.591\n",
      "\n",
      "EPOCHS 98..\n",
      "training_accuracy = 0.592\n",
      "validation_accuracy = 0.592\n",
      "\n",
      "EPOCHS 99..\n",
      "training_accuracy = 0.594\n",
      "validation_accuracy = 0.594\n",
      "\n",
      "EPOCHS 100..\n",
      "training_accuracy = 0.598\n",
      "validation_accuracy = 0.598\n",
      "\n",
      "model_saved\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    X_train_PCA, y_train = shuffle(X_train_PCA, y_train)\n",
    "    for i in range(EPOCHS):\n",
    "        sess.run(training_op, feed_dict={X: X_train_PCA, y: y_train, class_w: class_weights})\n",
    "        \n",
    "        training_accuracy = evaluate(X_train_PCA, y_train, class_weights)\n",
    "        validation_accuracy = evaluate(X_test_PCA, y_test, class_weights)\n",
    "        print ('EPOCHS {}..'.format(i+1))\n",
    "        print ('training_accuracy = {:.3f}'.format(validation_accuracy))\n",
    "        print ('validation_accuracy = {:.3f}'.format(validation_accuracy))\n",
    "        print ()\n",
    "        \n",
    "    saver.save(sess, 'model')\n",
    "    print ('model_saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ..., 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "    predictions = tf.argmax(logits,1)\n",
    "    print(sess.run(predictions, feed_dict={X: X_test_PCA}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
