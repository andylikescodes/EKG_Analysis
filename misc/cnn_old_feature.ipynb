{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#import python packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'detect_peaks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f95c4849549d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#import EKG analysis packages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwave\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mchallengeOld\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Work/Documents/physionet challenge/EKG_Analysis/misc/challengeOld.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mwaveOld\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwave\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Work/Documents/physionet challenge/EKG_Analysis/misc/waveOld.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdetect_peaks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdetect_peaks\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdetect_peaks_orig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbiosppy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignals\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mecg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'detect_peaks'"
     ]
    }
   ],
   "source": [
    "#import EKG analysis packages\n",
    "import wave\n",
    "import challengeOld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "records = wave.getRecords('All')\n",
    "feat_list = []\n",
    "for record in records[0]:\n",
    "    signal = challengeOld.Signal(record, wave.load(record))\n",
    "    feat_list.append(challengeOld.feature_extract(signal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "variance = data_test[:,3]\n",
    "mean_variance = np.mean(variance)\n",
    "normalize = (variance - mean_variance)/mean_variance\n",
    "data_test[:,3] = normalize\n",
    "\n",
    "variance = data_train[:,3]\n",
    "mean_variance = np.mean(variance)\n",
    "normalize = (variance - mean_variance)/mean_variance\n",
    "data_train[:,3] = normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#change the answer to integer classes\n",
    "answer_test_int = []\n",
    "answer_train_int = []\n",
    "for answer in answer_test:\n",
    "    if answer == 'N':\n",
    "        answer_test_int.append(0)\n",
    "    elif answer == 'O':\n",
    "        answer_test_int.append(1)\n",
    "    elif answer == 'A':\n",
    "        answer_test_int.append(2)\n",
    "    elif answer == '~':\n",
    "        answer_test_int.append(3)\n",
    "\n",
    "for answer in answer_train:\n",
    "    if answer == 'N':\n",
    "        answer_train_int.append(0)\n",
    "    elif answer == 'O':\n",
    "        answer_train_int.append(1)\n",
    "    elif answer == 'A':\n",
    "        answer_train_int.append(2)\n",
    "    elif answer == '~':\n",
    "        answer_train_int.append(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 128\n",
    "learning_rate = 0.0001\n",
    "num_examples = len(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.int32)\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "one_hot_y = tf.one_hot(y, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fw1 = tf.Variable(tf.truncated_normal([4, 8], mean=0, stddev=0.1))\n",
    "fb1 = tf.Variable(tf.zeros([8]))\n",
    "fw2 = tf.Variable(tf.truncated_normal([8, 8], mean=0, stddev=0.1))\n",
    "fb2 = tf.Variable(tf.zeros([8]))\n",
    "fw3 = tf.Variable(tf.truncated_normal([8, 4], mean=0, stddev=0.1))\n",
    "fb3 = tf.Variable(tf.zeros([4]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#fully connect layer 1, 4 => 8\n",
    "fully_layer_1 = tf.add(tf.matmul(X, fw1), fb1)\n",
    "fully_layer_1 = tf.nn.relu(fully_layer_1)\n",
    "#fully_layer_1 = tf.nn.dropout(fully_layer_1, keep_prob)\n",
    "\n",
    "#fully connect layer 2, 8 => 8\n",
    "fully_layer_2 = tf.add(tf.matmul(fully_layer_1, fw2), fb2)\n",
    "fully_layer_2 = tf.nn.relu(fully_layer_2)\n",
    "#fully_layer_2 = tf.nn.dropout(fully_layer_2, keep_prob)\n",
    "\n",
    "#output layer => 4 => 4\n",
    "logits = tf.add(tf.matmul(fully_layer_2, fw3), fb3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#train the model\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss_operation)\n",
    "\n",
    "#accuracy and loss\n",
    "correct_prediction = tf.equal(tf.argmax(logits,1), tf.argmax(one_hot_y,1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_X, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={X: batch_X, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_X))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS 1..\n",
      "validation_accuracy = 0.271\n",
      "\n",
      "EPOCHS 2..\n",
      "validation_accuracy = 0.277\n",
      "\n",
      "EPOCHS 3..\n",
      "validation_accuracy = 0.286\n",
      "\n",
      "EPOCHS 4..\n",
      "validation_accuracy = 0.290\n",
      "\n",
      "EPOCHS 5..\n",
      "validation_accuracy = 0.293\n",
      "\n",
      "EPOCHS 6..\n",
      "validation_accuracy = 0.302\n",
      "\n",
      "EPOCHS 7..\n",
      "validation_accuracy = 0.302\n",
      "\n",
      "EPOCHS 8..\n",
      "validation_accuracy = 0.304\n",
      "\n",
      "EPOCHS 9..\n",
      "validation_accuracy = 0.313\n",
      "\n",
      "EPOCHS 10..\n",
      "validation_accuracy = 0.314\n",
      "\n",
      "EPOCHS 11..\n",
      "validation_accuracy = 0.317\n",
      "\n",
      "EPOCHS 12..\n",
      "validation_accuracy = 0.321\n",
      "\n",
      "EPOCHS 13..\n",
      "validation_accuracy = 0.322\n",
      "\n",
      "EPOCHS 14..\n",
      "validation_accuracy = 0.328\n",
      "\n",
      "EPOCHS 15..\n",
      "validation_accuracy = 0.333\n",
      "\n",
      "EPOCHS 16..\n",
      "validation_accuracy = 0.337\n",
      "\n",
      "EPOCHS 17..\n",
      "validation_accuracy = 0.341\n",
      "\n",
      "EPOCHS 18..\n",
      "validation_accuracy = 0.342\n",
      "\n",
      "EPOCHS 19..\n",
      "validation_accuracy = 0.345\n",
      "\n",
      "EPOCHS 20..\n",
      "validation_accuracy = 0.350\n",
      "\n",
      "EPOCHS 21..\n",
      "validation_accuracy = 0.355\n",
      "\n",
      "EPOCHS 22..\n",
      "validation_accuracy = 0.357\n",
      "\n",
      "EPOCHS 23..\n",
      "validation_accuracy = 0.358\n",
      "\n",
      "EPOCHS 24..\n",
      "validation_accuracy = 0.364\n",
      "\n",
      "EPOCHS 25..\n",
      "validation_accuracy = 0.369\n",
      "\n",
      "EPOCHS 26..\n",
      "validation_accuracy = 0.373\n",
      "\n",
      "EPOCHS 27..\n",
      "validation_accuracy = 0.376\n",
      "\n",
      "EPOCHS 28..\n",
      "validation_accuracy = 0.380\n",
      "\n",
      "EPOCHS 29..\n",
      "validation_accuracy = 0.381\n",
      "\n",
      "EPOCHS 30..\n",
      "validation_accuracy = 0.390\n",
      "\n",
      "EPOCHS 31..\n",
      "validation_accuracy = 0.421\n",
      "\n",
      "EPOCHS 32..\n",
      "validation_accuracy = 0.442\n",
      "\n",
      "EPOCHS 33..\n",
      "validation_accuracy = 0.448\n",
      "\n",
      "EPOCHS 34..\n",
      "validation_accuracy = 0.449\n",
      "\n",
      "EPOCHS 35..\n",
      "validation_accuracy = 0.456\n",
      "\n",
      "EPOCHS 36..\n",
      "validation_accuracy = 0.461\n",
      "\n",
      "EPOCHS 37..\n",
      "validation_accuracy = 0.462\n",
      "\n",
      "EPOCHS 38..\n",
      "validation_accuracy = 0.463\n",
      "\n",
      "EPOCHS 39..\n",
      "validation_accuracy = 0.465\n",
      "\n",
      "EPOCHS 40..\n",
      "validation_accuracy = 0.467\n",
      "\n",
      "EPOCHS 41..\n",
      "validation_accuracy = 0.470\n",
      "\n",
      "EPOCHS 42..\n",
      "validation_accuracy = 0.471\n",
      "\n",
      "EPOCHS 43..\n",
      "validation_accuracy = 0.475\n",
      "\n",
      "EPOCHS 44..\n",
      "validation_accuracy = 0.483\n",
      "\n",
      "EPOCHS 45..\n",
      "validation_accuracy = 0.491\n",
      "\n",
      "EPOCHS 46..\n",
      "validation_accuracy = 0.498\n",
      "\n",
      "EPOCHS 47..\n",
      "validation_accuracy = 0.505\n",
      "\n",
      "EPOCHS 48..\n",
      "validation_accuracy = 0.510\n",
      "\n",
      "EPOCHS 49..\n",
      "validation_accuracy = 0.509\n",
      "\n",
      "EPOCHS 50..\n",
      "validation_accuracy = 0.511\n",
      "\n",
      "EPOCHS 51..\n",
      "validation_accuracy = 0.515\n",
      "\n",
      "EPOCHS 52..\n",
      "validation_accuracy = 0.517\n",
      "\n",
      "EPOCHS 53..\n",
      "validation_accuracy = 0.521\n",
      "\n",
      "EPOCHS 54..\n",
      "validation_accuracy = 0.525\n",
      "\n",
      "EPOCHS 55..\n",
      "validation_accuracy = 0.526\n",
      "\n",
      "EPOCHS 56..\n",
      "validation_accuracy = 0.530\n",
      "\n",
      "EPOCHS 57..\n",
      "validation_accuracy = 0.533\n",
      "\n",
      "EPOCHS 58..\n",
      "validation_accuracy = 0.537\n",
      "\n",
      "EPOCHS 59..\n",
      "validation_accuracy = 0.544\n",
      "\n",
      "EPOCHS 60..\n",
      "validation_accuracy = 0.544\n",
      "\n",
      "EPOCHS 61..\n",
      "validation_accuracy = 0.546\n",
      "\n",
      "EPOCHS 62..\n",
      "validation_accuracy = 0.549\n",
      "\n",
      "EPOCHS 63..\n",
      "validation_accuracy = 0.549\n",
      "\n",
      "EPOCHS 64..\n",
      "validation_accuracy = 0.553\n",
      "\n",
      "EPOCHS 65..\n",
      "validation_accuracy = 0.557\n",
      "\n",
      "EPOCHS 66..\n",
      "validation_accuracy = 0.558\n",
      "\n",
      "EPOCHS 67..\n",
      "validation_accuracy = 0.558\n",
      "\n",
      "EPOCHS 68..\n",
      "validation_accuracy = 0.559\n",
      "\n",
      "EPOCHS 69..\n",
      "validation_accuracy = 0.561\n",
      "\n",
      "EPOCHS 70..\n",
      "validation_accuracy = 0.561\n",
      "\n",
      "EPOCHS 71..\n",
      "validation_accuracy = 0.562\n",
      "\n",
      "EPOCHS 72..\n",
      "validation_accuracy = 0.563\n",
      "\n",
      "EPOCHS 73..\n",
      "validation_accuracy = 0.565\n",
      "\n",
      "EPOCHS 74..\n",
      "validation_accuracy = 0.565\n",
      "\n",
      "EPOCHS 75..\n",
      "validation_accuracy = 0.568\n",
      "\n",
      "EPOCHS 76..\n",
      "validation_accuracy = 0.569\n",
      "\n",
      "EPOCHS 77..\n",
      "validation_accuracy = 0.569\n",
      "\n",
      "EPOCHS 78..\n",
      "validation_accuracy = 0.568\n",
      "\n",
      "EPOCHS 79..\n",
      "validation_accuracy = 0.569\n",
      "\n",
      "EPOCHS 80..\n",
      "validation_accuracy = 0.572\n",
      "\n",
      "EPOCHS 81..\n",
      "validation_accuracy = 0.573\n",
      "\n",
      "EPOCHS 82..\n",
      "validation_accuracy = 0.575\n",
      "\n",
      "EPOCHS 83..\n",
      "validation_accuracy = 0.576\n",
      "\n",
      "EPOCHS 84..\n",
      "validation_accuracy = 0.576\n",
      "\n",
      "EPOCHS 85..\n",
      "validation_accuracy = 0.576\n",
      "\n",
      "EPOCHS 86..\n",
      "validation_accuracy = 0.576\n",
      "\n",
      "EPOCHS 87..\n",
      "validation_accuracy = 0.576\n",
      "\n",
      "EPOCHS 88..\n",
      "validation_accuracy = 0.576\n",
      "\n",
      "EPOCHS 89..\n",
      "validation_accuracy = 0.576\n",
      "\n",
      "EPOCHS 90..\n",
      "validation_accuracy = 0.577\n",
      "\n",
      "EPOCHS 91..\n",
      "validation_accuracy = 0.577\n",
      "\n",
      "EPOCHS 92..\n",
      "validation_accuracy = 0.577\n",
      "\n",
      "EPOCHS 93..\n",
      "validation_accuracy = 0.577\n",
      "\n",
      "EPOCHS 94..\n",
      "validation_accuracy = 0.577\n",
      "\n",
      "EPOCHS 95..\n",
      "validation_accuracy = 0.577\n",
      "\n",
      "EPOCHS 96..\n",
      "validation_accuracy = 0.579\n",
      "\n",
      "EPOCHS 97..\n",
      "validation_accuracy = 0.579\n",
      "\n",
      "EPOCHS 98..\n",
      "validation_accuracy = 0.579\n",
      "\n",
      "EPOCHS 99..\n",
      "validation_accuracy = 0.579\n",
      "\n",
      "EPOCHS 100..\n",
      "validation_accuracy = 0.579\n",
      "\n",
      "model_saved\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    data_train, answer_train_int = shuffle(data_train, answer_train_int)\n",
    "    for i in range(EPOCHS):\n",
    "        sess.run(training_op, feed_dict={X: data_train, y: answer_train_int})\n",
    "        \n",
    "        validation_accuracy = evaluate(data_test, answer_test_int)\n",
    "        print ('EPOCHS {}..'.format(i+1))\n",
    "        print ('validation_accuracy = {:.3f}'.format(validation_accuracy))\n",
    "        print ()\n",
    "        \n",
    "    saver.save(sess, 'model')\n",
    "    print ('model_saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 3 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0\n",
      " 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 3 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0\n",
      " 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "    predictions = tf.argmax(logits,1)\n",
    "    print(sess.run(predictions, feed_dict={X: data_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
